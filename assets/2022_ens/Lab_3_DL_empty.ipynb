{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "288c099b-0bc0-4650-a73e-693d7d39a1bb",
   "metadata": {},
   "source": [
    "# Automatic differentiation and Deep Learning basics, with pytorch\n",
    "\n",
    "Author: Mathurin Massias\n",
    "\n",
    "\n",
    "Pytorch (torch) has become the standard library for DL, and surpassed Tensorflow (see e.g. https://paperswithcode.com/trends). A recent alternative, JAX, has emerged and is showing quick adoption. This lab focuses on pytorch.\n",
    "\n",
    "### Working on GPU\n",
    "Training neural networks is much faster on GPU. If you want to experiment with GPUs, you can upload this notebook to the google colab platform and run it there.\n",
    "Colab provides free GPU resources. \n",
    "- Go to https://colab.research.google.com\n",
    "- Upload this notebook \n",
    "- Open it\n",
    "- Navigate to Editâ†’Notebook Settings\n",
    "- select T4 GPU from the Hardware Accelerator list\n",
    "\n",
    "You can check GPU availability with:\n",
    "```\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "```\n",
    "The last line is a standard torch practice, that allows writing code which will work on GPU if available, else fall back to CPU.\n",
    "\n",
    "\n",
    "By default, models and tensors are stored on CPU. To move them to GPU, use \n",
    "```\n",
    "my_tensor = my_tensor.to(device)\n",
    "model.to(device)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92617e67-1dfe-4a4d-b5f1-17710a1d7092",
   "metadata": {},
   "source": [
    "## Pytorch basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7bb2ba-725a-48b3-aa39-b6a7e96055f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880e6f9f-7f8b-421c-a4a7-c93342b8c269",
   "metadata": {},
   "source": [
    "Torch works with tensors, which are n-dimensional arrays. They work a lot like the famous numpy.ndarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8130bd-c35e-48fa-bd22-972b22367503",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros(3, 5)  # like np.zeros\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bda8c1f-9b7d-42aa-a639-3e7457923e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2406)  # equivalent of np.random.seed\n",
    "y = torch.randn(3, 5, 2)  # like np.random.randn\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4dd77b-79e3-46b8-abc5-294b07d789c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0, ::2]  # slicing like a np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4ee73d-9188-4b30-8fb5-22ce85793d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.ones_like(x)  # like np.ones_like \n",
    "print(x - 2 * z)  # pointwise operations are supported"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05063973-5a69-40e4-819d-76bcc1394bcd",
   "metadata": {},
   "source": [
    "The key functionality of pytorch is its use of backpropagation (reverse mode automatic differentiation) to compute gradients of any function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9133c6d6-50aa-401b-9acd-91f5a98b4a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with `requires_grad`, we tell torch that together with these tensors, we'll need to store gradients\n",
    "A = torch.randn(6, 5, requires_grad=True)\n",
    "b = torch.arange(6, requires_grad=True, dtype=torch.float32) \n",
    "\n",
    "x = torch.randn(5, requires_grad=True)\n",
    "\n",
    "fun = 0.5 * ((A @ x - b) ** 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23c9592-12b4-4588-9220-66597f2b0eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fun.backward()  # this computes the gradient of `fun`, with AD, with respect to all the variables in the computational graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cb83f2-5976-4adb-ace5-0ca1e181665c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27316caf-00c7-441e-84f7-98c676136654",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.T @ (A @ x - b)  # matches x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e765e8d1-f1cc-4c39-8c80-54ed5dfc45d4",
   "metadata": {},
   "source": [
    "but we also have the gradient of `fun` with respect to `A` and `b`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120c1137-2d3d-4957-883d-dee2b5b8bfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.grad  # equals b - A @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250cde0e-deab-4cd4-9818-16179af4b48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b - A @ x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f20be0-9a89-4692-bef7-0dfc5430a16e",
   "metadata": {},
   "source": [
    "Q1) On paper, compute the gradient of `fun` with respect to $A$ (identified by an $n \\times d$ matrix). Compute it with pytorch and check numerically that it is equal to the value you found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc209b2b-2575-48cb-804c-a8464fb34e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af375f9c-e9a9-46c9-ba24-3505ca74f552",
   "metadata": {},
   "source": [
    "The `.backward()` function is of primal importance, as it allows computing in one go the gradient of the loss of a neural network with respect to all the weights in the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38f3ae3-10c2-48c3-8593-0380d1c1309c",
   "metadata": {},
   "source": [
    "Q2) Generate a random $100 \\times 200$ matrix $A$ and vectors $x$ and $b$ of adequate size and content, in order to compute the gradient of the logistic loss at $x$ with automatic differentiation.\n",
    "\n",
    "Compare the time it takes to compute the gradient with autodiff and with the mathematical formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0159a9f7-bb5a-4ab3-87cf-2d24ef7fe52a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "139c7b79-5abe-4dbd-9380-0afe496784c5",
   "metadata": {},
   "source": [
    "Q3) Code gradient descent on the logistic regression problem, using automatic differentiation to compute the gradient at each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4775b96-851f-475e-97b5-1a341ec26bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "303ce8cc-27c0-4daf-b1e2-41969697d41e",
   "metadata": {},
   "source": [
    "### Basic Neural Network \n",
    "\n",
    "In the sequel we'll define a very simple, fully connected neural network. Usually neural networks are defined as classes, inheriting from `torch.nn.Module`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c003f172-fa9c-4e33-a681-8a0d9fed11f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn \n",
    "\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 100)\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "        self.fc3 = nn.Linear(10, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Apply network to input x.\"\"\"\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d298f8-8717-4f97-8486-b5da5283837e",
   "metadata": {},
   "source": [
    "Q4) Is a bias (constant term) included in pytorch Linear layer? If the input of a layer is `x`, what is the output? \n",
    "How are the layers weights initialized? Why does it matter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d860fb40-de81-486d-bfd9-6fed60400e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd08a5ef-8472-4e20-ad92-88309b7c94fa",
   "metadata": {},
   "source": [
    "Q5) Plot the output of your network on the segment [-2, 2]. Try the straightforward approach, and read carefully the error message that may pop up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092a777e-869f-43b0-ba17-a845cd43b3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mynet = MyNet()\n",
    "x = torch.linspace(-2, 2, 100)[:, None]  # beware: shape must be (batch_size, dimension)\n",
    "y = mynet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b7e5e5-9f10-4116-a8f2-4b8f61c993ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f85f20ad-7c6a-4a50-98e9-1b38b0adb750",
   "metadata": {},
   "source": [
    "### Fitting a sine \n",
    "First, let's generate some 1 dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf965ba-1813-429e-bae3-29e10e85a79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(10_000, 1)\n",
    "y = torch.sin(np.pi * X[:, 0]) + 0.1 * torch.randn(X.shape[0])\n",
    "\n",
    "plt.scatter(X[:100, 0], y[:100]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81027875-423b-4967-baf5-559d4194e95b",
   "metadata": {},
   "source": [
    "We wrap our dataset in a util called `DataLoader`, that allows enumerating over the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f884b3-a0f5-4611-8ce4-3a522d790e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train = DataLoader(TensorDataset(X, y), batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01984246-3312-419c-af02-e0e6eaa14999",
   "metadata": {},
   "source": [
    "Let's train our network with SGD. \n",
    "\n",
    "Fix the code below to make it work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479e054d-18da-456d-93d3-530052367ef2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.optim import SGD \n",
    "mse = nn.MSELoss()\n",
    "mynet = MyNet()\n",
    "\n",
    "optimizer = SGD(mynet.parameters(), lr=10, momentum=0.9)\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    av_loss = []\n",
    "    for input, target in train: \n",
    "        loss = mse(mynet(input), target[:, None])\n",
    "        av_loss.append(loss.detach().numpy())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch}, av loss {np.mean(av_loss):.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4be7d0-eac4-417a-9536-111c0c32c36a",
   "metadata": {},
   "source": [
    "Visualize the output of your network on the segment  [-2, 2]. Comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8122c8-6884-45ab-8de0-ecd359e1268f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "169d84e8-6f63-42e1-86f2-23554fa55eb0",
   "metadata": {},
   "source": [
    "Q6) Split the data into a training a testing part. \n",
    "Retrain your model, logging the training and testing losses across epochs. Plot them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cf055f-3256-4280-9df8-a8d88d37c283",
   "metadata": {},
   "source": [
    "Q7) Run ADAM instead of SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dd8a28-c8a8-4383-84bc-7d3bf8b80f86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
